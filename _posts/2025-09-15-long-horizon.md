---
layout: post
title:  "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs"
date:   2025-08-01 12:00:00 +00:00
categories: research
authors: "<strong>Akshit Sinha</strong>*, Arvindh Arun*, Shashwat Goel*, Steffen Staab, Jonas Geiping"
image: /images/lhs.png
venue: "Preprint"
code: https://github.com/long-horizon-execution/measuring-execution
arxiv: https://arxiv.org/abs/2509.09677
---
We show several interesting results that challenge common assumptions about the capabilities of LLMs for long-horizon tasks. We find that (1) Scaling model size hugely improves long-horizon performance, (2) LLMs can effectively utilize intermediate steps to improve performance, and (3) LLMs struggle with what we call "self-conditioning", where if they see more errors in their context, the make more errors in future steps. We find that intermediate reasoning steps can help mitigate this issue. Overall, our results suggest that LLMs have significant untapped potential for long-horizon tasks, and that with the right techniques, they can perform much better than previously thought.